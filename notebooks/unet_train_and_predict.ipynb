{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instant segmentation with U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import (\n",
    "    Resize,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    HorizontalFlip,\n",
    "    RandomBrightnessContrast,\n",
    ")\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.image_paths = sorted(list(Path(images_dir).glob(\"*.jpg\")))\n",
    "        self.mask_paths = sorted(list(Path(masks_dir).glob(\"*.png\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        mask_path = self.mask_paths[idx]\n",
    "\n",
    "        # Load image and mask\n",
    "        image = cv2.imread(str(image_path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        # Normalize mask (binary: 0 or 1)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0) / 255.0\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data augmentation during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training augmentations\n",
    "train_transform = Compose(\n",
    "    [\n",
    "        HorizontalFlip(p=0.5),\n",
    "        RandomBrightnessContrast(p=0.2),\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Resize(512, 512),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Validation augmentations\n",
    "val_transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Resize(512, 512),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_dir = \"../data/model_training/split/train/images\"\n",
    "train_masks_dir = \"../data/model_training/split/train/masks\"\n",
    "val_images_dir = \"../data/model_training/split/val/images\"\n",
    "val_masks_dir = \"../data/model_training/split/val/masks\"\n",
    "test_images_dir = \"../data/model_training/split/test/images\"\n",
    "test_masks_dir = \"../data/split/model_training/test/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(train_images_dir, train_masks_dir, transform=train_transform)\n",
    "val_dataset = SegmentationDataset(val_images_dir, val_masks_dir, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "# Define the U-Net model\n",
    "model = Unet(\n",
    "    encoder_name=\"resnet34\",  # Encoder backbone\n",
    "    encoder_weights=\"imagenet\",  # Pretrained on ImageNet\n",
    "    in_channels=3,  # Input channels (RGB)\n",
    "    classes=1,  # Output channels (binary segmentation)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cells if you want train the model, otherwise go to Section 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "# Device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path=\"unet_model.pth\"):\n",
    "    checkpoint = {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Checkpoint saved at epoch {epoch} to {path}\")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Save checkpoint at the end of training\n",
    "save_checkpoint(model, optimizer, num_epochs, path=\"unet_model.pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def visualize_test_results(model, dataloader, num_samples=10):\n",
    "    \"\"\"\n",
    "    Visualizes random test results by displaying original images, true masks, and predicted masks.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): Trained model for inference.\n",
    "        dataloader (DataLoader): DataLoader containing test dataset.\n",
    "        num_samples (int): Number of random samples to visualize.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Flatten the dataset into a list of indices\n",
    "    dataset_indices = list(range(len(dataloader.dataset)))\n",
    "\n",
    "    # Randomly sample indices\n",
    "    selected_indices = random.sample(\n",
    "        dataset_indices, min(num_samples, len(dataset_indices))\n",
    "    )\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx in selected_indices:\n",
    "            # Retrieve the image and mask at the selected index\n",
    "            image, mask = dataloader.dataset[idx]\n",
    "\n",
    "            # Convert to device and add batch dimension\n",
    "            image_tensor = image.unsqueeze(0).to(device)\n",
    "            mask_tensor = mask.unsqueeze(0).to(device)\n",
    "\n",
    "            # Model prediction\n",
    "            output = model(image_tensor)\n",
    "            pred = (torch.sigmoid(output) > 0.5).float()\n",
    "\n",
    "            # Visualize\n",
    "            plt.figure(figsize=(12, 6))\n",
    "\n",
    "            # Original image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # True mask\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(mask.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "            plt.title(\"True Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            # Predicted mask\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(pred.squeeze().cpu().numpy(), cmap=\"gray\")\n",
    "            plt.title(\"Predicted Mask\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models_pytorch import Unet\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = Unet(encoder_name=\"resnet34\", in_channels=3, classes=1).to(device)\n",
    "model.load_state_dict(torch.load(\"../checkpoints/unet_model.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_transform = Compose(\n",
    "    [\n",
    "        Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        Resize(512, 512),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SegmentationDataset(\n",
    "    test_images_dir, test_masks_dir, transform=test_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 3. Visualize predictions\n",
    "for images, masks in test_loader:\n",
    "    images, masks = images.to(device), masks.to(device)\n",
    "    outputs = model(images)\n",
    "    preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "    visualize_test_results(model, test_loader, num_samples=10)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Evaluation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import directed_hausdorff\n",
    "\n",
    "\n",
    "def compute_metrics(model, dataloader):\n",
    "    model.eval()\n",
    "    iou_scores = []\n",
    "    dice_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    hausdorff_distances = []\n",
    "    mae_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "            # Compute metrics for each sample\n",
    "            for pred, mask in zip(preds, masks):\n",
    "                intersection = (pred * mask).sum().item()\n",
    "                pred_sum = pred.sum().item()\n",
    "                mask_sum = mask.sum().item()\n",
    "                union = pred_sum + mask_sum - intersection\n",
    "\n",
    "                # IoU\n",
    "                iou = intersection / (union + 1e-6)\n",
    "                iou_scores.append(iou)\n",
    "\n",
    "                # Dice\n",
    "                dice = 2 * intersection / (pred_sum + mask_sum + 1e-6)\n",
    "                dice_scores.append(dice)\n",
    "\n",
    "                # Precision and Recall\n",
    "                tp = intersection\n",
    "                fp = pred_sum - intersection\n",
    "                fn = mask_sum - intersection\n",
    "                precision = tp / (tp + fp + 1e-6)\n",
    "                recall = tp / (tp + fn + 1e-6)\n",
    "                precision_scores.append(precision)\n",
    "                recall_scores.append(recall)\n",
    "\n",
    "                # F1 Score\n",
    "                f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "                f1_scores.append(f1)\n",
    "\n",
    "                # Mean Absolute Error (MAE)\n",
    "                mae = torch.abs(pred - mask).mean().item()\n",
    "                mae_scores.append(mae)\n",
    "\n",
    "                # Hausdorff Distance\n",
    "                pred_indices = torch.nonzero(pred, as_tuple=False).cpu().numpy()\n",
    "                mask_indices = torch.nonzero(mask, as_tuple=False).cpu().numpy()\n",
    "                if len(pred_indices) > 0 and len(mask_indices) > 0:\n",
    "                    hd = max(\n",
    "                        directed_hausdorff(pred_indices, mask_indices)[0],\n",
    "                        directed_hausdorff(mask_indices, pred_indices)[0],\n",
    "                    )\n",
    "                else:\n",
    "                    hd = float(\"inf\")  # Handle case with empty prediction or mask\n",
    "                hausdorff_distances.append(hd)\n",
    "\n",
    "    # Calculate mean metrics\n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_mae = np.mean(mae_scores)\n",
    "    # mean_hausdorff = np.mean(hausdorff_distances)\n",
    "    mean_hausdorff = np.mean([d for d in hausdorff_distances if d != float(\"inf\")])\n",
    "\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "    print(f\"Mean F1-Score: {mean_f1:.4f}\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f}\")\n",
    "    print(f\"Mean Hausdorff Distance: {mean_hausdorff:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"iou\": mean_iou,\n",
    "        \"dice\": mean_dice,\n",
    "        \"precision\": mean_precision,\n",
    "        \"recall\": mean_recall,\n",
    "        \"f1\": mean_f1,\n",
    "        \"mae\": mean_mae,\n",
    "        \"hausdorff\": mean_hausdorff,\n",
    "    }\n",
    "\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_images_dir = \"../data/model_training/split/test/images\"\n",
    "test_masks_dir = \"../data/model_training/split/test/masks\"\n",
    "test_dataset = SegmentationDataset(\n",
    "    test_images_dir, test_masks_dir, transform=val_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "# Evaluate on the test set\n",
    "metrics = compute_metrics(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Best and worse prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prediction(title, data):\n",
    "    \"\"\"\n",
    "    Display a single prediction with ground truth and mask.\n",
    "    Args:\n",
    "        title: Title of the display (e.g., 'Best Prediction').\n",
    "        data: Tuple containing image, prediction mask, ground truth mask, index, and IoU.\n",
    "    Returns:\n",
    "        None (displays the image with masks).\n",
    "    \"\"\"\n",
    "    if data is None:\n",
    "        print(f\"No {title} found.\")\n",
    "        return\n",
    "\n",
    "    image, prediction_mask, ground_truth_mask, idx, iou = data\n",
    "    # Convert image to numpy and scale to [0, 255]\n",
    "    image_np = image.cpu().numpy().transpose(1, 2, 0)  # Convert CHW to HWC\n",
    "    #image_np = (image_np * 255).astype(np.uint8)  # Scale to 0-255 for display\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.suptitle(f\"{title} (IoU: {iou:.4f})\")\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Display ground truth mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    gt_mask_np = ground_truth_mask.squeeze().cpu().numpy()  # Remove channel dimension if present\n",
    "    plt.imshow(gt_mask_np, cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Display predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    pred_mask_np = prediction_mask.squeeze().cpu().numpy()  # Remove channel dimension if present\n",
    "    plt.imshow(pred_mask_np, cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_and_worst_predictions_unet(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate U-Net model on the test dataset and find the best and worst predictions.\n",
    "    Args:\n",
    "        model: U-Net model.\n",
    "        dataloader: DataLoader for the test dataset.\n",
    "    Returns:\n",
    "        None (displays the best and worst predictions with their masks).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    best_iou = -float(\"inf\")\n",
    "    worst_iou = float(\"inf\")\n",
    "    best_data = None\n",
    "    worst_data = None\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (images, ground_truth_mask) in enumerate(dataloader):\n",
    "            # Move data to the device\n",
    "            images, ground_truth_mask = images.to(device), ground_truth_mask.to(device)\n",
    "\n",
    "            # Predict using U-Net\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()  # Binarize predictions\n",
    "\n",
    "            # Compute IoU for each image in the batch\n",
    "            for i in range(images.size(0)):\n",
    "                pred = preds[i]\n",
    "                gt_mask = ground_truth_mask[i]\n",
    "\n",
    "                intersection = (pred * gt_mask).sum().item()\n",
    "                union = (pred + gt_mask).sum().item() - intersection\n",
    "                iou = intersection / (union + 1e-6)\n",
    "\n",
    "                # Update best and worst predictions\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_data = (images[i], pred, gt_mask, idx, iou)\n",
    "\n",
    "                if iou < worst_iou:\n",
    "                    worst_iou = iou\n",
    "                    worst_data = (images[i], pred, gt_mask, idx, iou)\n",
    "\n",
    "    # Display results\n",
    "    display_prediction(\"Best Prediction\", best_data)\n",
    "    display_prediction(\"Worst Prediction\", worst_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = \"../data/model_training/split/test/images\"\n",
    "test_masks_dir = \"../data/model_training/split/test/masks\"\n",
    "test_dataset = SegmentationDataset(\n",
    "    test_images_dir, test_masks_dir, transform=val_transform\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "# Evaluate and display best/worst predictions\n",
    "find_best_and_worst_predictions_unet(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
