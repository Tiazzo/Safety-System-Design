{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation with YOLO \n",
    "\n",
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.spatial.distance import directed_hausdorff\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set best trained YOLO model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"../checkpoints/best_yolo_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, transform=None, img_size=640):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.image_filenames = sorted(os.listdir(images_dir))\n",
    "        self.mask_filenames = sorted(os.listdir(masks_dir))\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size  # Ensure dimensions are divisible by 32\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        mask_path = os.path.join(self.masks_dir, self.mask_filenames[idx])\n",
    "\n",
    "        # Load image and mask\n",
    "        image = cv2.imread(image_path)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Resize image and mask\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size))\n",
    "        mask = cv2.resize(mask, (self.img_size, self.img_size))\n",
    "\n",
    "        # Convert mask to binary\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image, mask = transformed['image'], transformed['mask']\n",
    "\n",
    "        # Normalize and format image for YOLO\n",
    "        image = image.transpose(2, 0, 1) / 255.0  # HWC to CHW and normalize to [0, 1]\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "        return image, mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize one prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(\n",
    "    source=\"../data/model_training/split/test/images/A_Peu_06_aug_1.jpg\", #image\n",
    "    show=True, \n",
    "    save=False, \n",
    "    conf=0.3, \n",
    "    line_width=1, \n",
    "    save_crop=False, \n",
    "    save_txt=False, \n",
    "    show_boxes=True, \n",
    "    show_labels=True, \n",
    "    show_conf=True,\n",
    "    classes=[0] \n",
    ")\n",
    "\n",
    "masks = results[0].masks.data  \n",
    "\n",
    "# Display every window:\n",
    "for mask in masks:\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    plt.imshow(mask_np, cmap=\"gray\")  \n",
    "    plt.show()\n",
    "\n",
    "img_with_predictions = results[0].plot()\n",
    "plt.imshow(cv2.cvtColor(img_with_predictions, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evalution\n",
    "\n",
    "Compute performance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics_yolo_dataset(model, dataloader):\n",
    "    iou_scores = []\n",
    "    dice_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    mae_scores = []\n",
    "    hausdorff_distances = []\n",
    "\n",
    "    for images, ground_truth_mask in dataloader:\n",
    "        image = images[0].unsqueeze(0)  # Add batch dimension to match YOLO input format\n",
    "        ground_truth_mask = ground_truth_mask[0]  # Unpack batch dimension\n",
    "\n",
    "        # Predict using YOLO\n",
    "        results = model.predict(source=image, save=False, conf=0.3, classes=[0], show=False)\n",
    "        if results and results[0].masks is not None:\n",
    "            predictions = results[0].masks.data  # YOLO segmentation masks\n",
    "        else:\n",
    "            predictions = []\n",
    "\n",
    "        # Combine predicted masks\n",
    "        prediction_mask = torch.zeros_like(ground_truth_mask, dtype=torch.float32)\n",
    "        for mask in predictions:\n",
    "            mask_np = mask.cpu().numpy()\n",
    "            prediction_mask += torch.tensor(mask_np, dtype=torch.float32)\n",
    "\n",
    "        prediction_mask = (prediction_mask > 0.5).float()\n",
    "\n",
    "        # Compute metrics\n",
    "        intersection = (prediction_mask * ground_truth_mask).sum().item()\n",
    "        union = (prediction_mask + ground_truth_mask).sum().item() - intersection\n",
    "        pred_sum = prediction_mask.sum().item()\n",
    "        gt_sum = ground_truth_mask.sum().item()\n",
    "\n",
    "        # IoU\n",
    "        iou = intersection / (union + 1e-6)\n",
    "        iou_scores.append(iou)\n",
    "\n",
    "        # Dice\n",
    "        dice = 2 * intersection / (pred_sum + gt_sum + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "        # Precision and Recall\n",
    "        tp = intersection\n",
    "        fp = pred_sum - intersection\n",
    "        fn = gt_sum - intersection\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "\n",
    "        # F1 Score\n",
    "        f1 = 2 * precision * recall / (precision + recall + 1e-6)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = torch.abs(prediction_mask - ground_truth_mask).mean().item()\n",
    "        mae_scores.append(mae)\n",
    "\n",
    "        # Hausdorff Distance\n",
    "        pred_indices = torch.nonzero(prediction_mask, as_tuple=False).cpu().numpy()\n",
    "        gt_indices = torch.nonzero(ground_truth_mask, as_tuple=False).cpu().numpy()\n",
    "        if len(pred_indices) > 0 and len(gt_indices) > 0:\n",
    "            hausdorff = max(\n",
    "                directed_hausdorff(pred_indices, gt_indices)[0],\n",
    "                directed_hausdorff(gt_indices, pred_indices)[0],\n",
    "            )\n",
    "        else:\n",
    "            hausdorff = float(\"inf\")  # Handle case with empty prediction or mask\n",
    "        hausdorff_distances.append(hausdorff)\n",
    "\n",
    "    # Aggregate metrics\n",
    "    mean_iou = np.mean(iou_scores)\n",
    "    mean_dice = np.mean(dice_scores)\n",
    "    mean_precision = np.mean(precision_scores)\n",
    "    mean_recall = np.mean(recall_scores)\n",
    "    mean_f1 = np.mean(f1_scores)\n",
    "    mean_mae = np.mean(mae_scores)\n",
    "    mean_hausdorff = np.mean([d for d in hausdorff_distances if d != float(\"inf\")])  # Exclude inf\n",
    "\n",
    "    print(f\"Mean IoU: {mean_iou:.4f}\")\n",
    "    print(f\"Mean Dice: {mean_dice:.4f}\")\n",
    "    print(f\"Mean Precision: {mean_precision:.4f}\")\n",
    "    print(f\"Mean Recall: {mean_recall:.4f}\")\n",
    "    print(f\"Mean F1-Score: {mean_f1:.4f}\")\n",
    "    print(f\"Mean MAE: {mean_mae:.4f}\")\n",
    "    print(f\"Mean Hausdorff Distance: {mean_hausdorff:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"iou\": mean_iou,\n",
    "        \"dice\": mean_dice,\n",
    "        \"precision\": mean_precision,\n",
    "        \"recall\": mean_recall,\n",
    "        \"f1\": mean_f1,\n",
    "        \"mae\": mean_mae,\n",
    "        \"hausdorff\": mean_hausdorff,\n",
    "    }\n",
    "\n",
    "\n",
    "test_images_dir = \"../data/model_training/split/test/images\"\n",
    "test_masks_dir = \"../data/model_training/split/test/masks\"\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "test_dataset = YOLOTestDataset(test_images_dir, test_masks_dir, img_size=640)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "# Evaluate on the test set\n",
    "metrics = compute_metrics_yolo_dataset(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "present best and worst prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_best_and_worst_predictions(model, dataloader):\n",
    "    \"\"\"\n",
    "    Evaluate YOLO model on the test dataset and find the best and worst predictions.\n",
    "    Args:\n",
    "        model: YOLO model.\n",
    "        dataloader: DataLoader for the test dataset.\n",
    "    Returns:\n",
    "        None (displays the best and worst predictions with their masks).\n",
    "    \"\"\"\n",
    "    best_iou = -float(\"inf\")\n",
    "    worst_iou = float(\"inf\")\n",
    "    best_data = None\n",
    "    worst_data = None\n",
    "\n",
    "    for idx, (images, ground_truth_mask) in enumerate(dataloader):\n",
    "        # Prepare the image and mask\n",
    "        image = images[0].unsqueeze(0)  # Add batch dimension for YOLO\n",
    "        ground_truth_mask = ground_truth_mask[0]  # Unpack batch dimension\n",
    "\n",
    "        # Predict using YOLO\n",
    "        results = model.predict(source=image, save=False, conf=0.3, classes=[0], show=False)\n",
    "        if results and results[0].masks is not None:\n",
    "            predictions = results[0].masks.data  # YOLO segmentation masks\n",
    "        else:\n",
    "            predictions = []\n",
    "\n",
    "        # Combine predicted masks\n",
    "        prediction_mask = torch.zeros_like(ground_truth_mask, dtype=torch.float32)\n",
    "        for mask in predictions:\n",
    "            mask_np = mask.cpu().numpy()\n",
    "            prediction_mask += torch.tensor(mask_np, dtype=torch.float32)\n",
    "\n",
    "        prediction_mask = (prediction_mask > 0.5).float()\n",
    "\n",
    "        # Compute IoU\n",
    "        intersection = (prediction_mask * ground_truth_mask).sum().item()\n",
    "        union = (prediction_mask + ground_truth_mask).sum().item() - intersection\n",
    "        iou = intersection / (union + 1e-6)\n",
    "\n",
    "        # Update best and worst predictions\n",
    "        if iou > best_iou:\n",
    "            best_iou = iou\n",
    "            best_data = (image, prediction_mask, ground_truth_mask, idx, iou)\n",
    "\n",
    "        if iou < worst_iou:\n",
    "            worst_iou = iou\n",
    "            worst_data = (image, prediction_mask, ground_truth_mask, idx, iou)\n",
    "\n",
    "    # Display results\n",
    "    display_prediction(\"Best Prediction\", best_data)\n",
    "    display_prediction(\"Worst Prediction\", worst_data)\n",
    "\n",
    "\n",
    "def display_prediction(title, data):\n",
    "    \"\"\"\n",
    "    Display a single prediction with ground truth and mask.\n",
    "    Args:\n",
    "        title: Title of the display (e.g., 'Best Prediction').\n",
    "        data: Tuple containing image, prediction mask, ground truth mask, index, and IoU.\n",
    "    Returns:\n",
    "        None (displays the image with masks).\n",
    "    \"\"\"\n",
    "    if data is None:\n",
    "        print(f\"No {title} found.\")\n",
    "        return\n",
    "\n",
    "    image, prediction_mask, ground_truth_mask, idx, iou = data\n",
    "    image_np = image.squeeze(0).numpy().transpose(1, 2, 0) * 255  # Convert back to HWC format and scale to [0, 255]\n",
    "    image_np = image_np.astype(np.uint8)\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.suptitle(f\"{title} (IoU: {iou:.4f})\")\n",
    "\n",
    "    # Display original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Display ground truth mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(ground_truth_mask.cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Display predicted mask\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(prediction_mask.cpu().numpy(), cmap=\"gray\")\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "test_images_dir = \"../data/model_training/split/test/images\"\n",
    "test_masks_dir = \"../data/model_training/split/test/masks\"\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "test_dataset = YOLOTestDataset(test_images_dir, test_masks_dir, img_size=640)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Evaluate and display best/worst predictions\n",
    "find_best_and_worst_predictions(model, test_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
