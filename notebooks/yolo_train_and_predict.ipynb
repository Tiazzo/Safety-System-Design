{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Segmentation with YOLO11\n",
    "This notebook has two features:\n",
    "- Training a YOLO model on the dataset\n",
    "- Predicting with the trained YOLO model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialization\n",
    "Link to models: https://docs.ultralytics.com/tasks/segment/\n",
    "- We used **YOLO11m-seg**\n",
    "- Download it if you want to train the model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_pre_trained_model = \"CONFIGURE_PATH_TO_DOWNLOADED_MODEL\" # This is the model downloaded from the link provided above\n",
    "dataset = \"../data/model_training/YOLODataset/dataset.yaml\" \n",
    "path_to_trained_yolo_model = \"../checkpoints/best_yolo_model.pt\"\n",
    "output_folder = \"../data/predicted/YOLO/masks\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Convert Annotations from JSON to YOLO & Split Into Train, Val, and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT!**\n",
    "\n",
    "You should have **already completed the preprocessing steps** from the preprocess notebook. \n",
    "\n",
    "[labelme2yolo](https://pypi.org/project/labelme2yolo/) is used to split the dataset into train, test, and validation sets. The following code will set up labelme2yolo and run it to create training, testing, and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install labelme2yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme2yolo --json_dir \"../data/processed/scaled/labels\" --val_size 0.15 --test_size 0.15 --output_format polygon --seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = \"../data/processed/scaled/labels/YOLODataset\"\n",
    "destination_folder = \"../data/model_training\"\n",
    "\n",
    "os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    shutil.move(source_folder, destination_folder)\n",
    "    print(f\"Moved '{source_folder}' to '{destination_folder}'.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: {e}. Make sure the source folder exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewrite_dataset_yaml(yolo_dataset_path, yaml_file_path):\n",
    "    abs_path = os.path.abspath(yolo_dataset_path)\n",
    "\n",
    "    # New content for the YAML file\n",
    "    yaml_content = f\"\"\"\n",
    "path: {abs_path}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "names:\n",
    "    0: window\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with open(yaml_file_path, \"w\") as yaml_file:\n",
    "            yaml_file.write(yaml_content.strip())\n",
    "        print(f\"Rewritten dataset.yaml successfully at {yaml_file_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while writing to the file: {e}\")\n",
    "\n",
    "yolo_dataset_path = \"../data/model_training/YOLODataset\"  \n",
    "yaml_file_path = \"../data/model_training/YOLODataset/dataset.yaml\"    \n",
    "rewrite_dataset_yaml(yolo_dataset_path, yaml_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Train Model\n",
    "Results will be saved to the **root** of the project **/runs/train**\n",
    "\n",
    "\n",
    "Prerequisites:\n",
    "- You have configured a path to the pre-trained model, downloaded from the Ultralytics website\n",
    "- You have completely finished the preprocessing steps and followed the steps above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = YOLO(path_to_pre_trained_model) # Path to pre-trained model\n",
    "\n",
    "model.train(data = dataset, imgsz = 640, device = 0, batch = 8, epochs = 50, workers = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predict with Model\n",
    "Results will be saved to `../data/predicted/YOLO/masks`\n",
    "\n",
    "\n",
    "To see more inference arguments, please see:\n",
    "- https://docs.ultralytics.com/modes/predict/#inference-arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So images and graphs can be printed in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_yolo(image_path, output_folder=None, skip_display=True):\n",
    "    model = YOLO(path_to_trained_yolo_model) # Path to your trained model\n",
    "\n",
    "    results = model.predict(\n",
    "        source=image_path,  # Path to the single image you want to predict\n",
    "        show=False,         # Open image with drawn mask in a new window\n",
    "        save=False,         # Save image with drawn mask\n",
    "        conf=0.6,           # Minimum confidence score \n",
    "        line_width=1,       # Width of box line\n",
    "        save_crop=False,    # Save window crops \n",
    "        save_txt=False,     # Save bbox and segmentation label\n",
    "        show_boxes=True,    # Show bbox\n",
    "        show_labels=True,   # Show labels\n",
    "        show_conf=True,     # Show confidence score\n",
    "        classes=[0],        # Which classes to include (we only have 1, hence [0])\n",
    "        iou=0.6             # Minimum IoU score\n",
    "    )                       # More can be configured, please see provided link above\n",
    "\n",
    "    # Process and save predicted mask\n",
    "    masks = results[0].masks.data  \n",
    "\n",
    "    \n",
    "    image = cv2.imread(image_path)\n",
    "    height, width = image.shape[:2]\n",
    "    combined_mask = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    \n",
    "    for mask in masks:\n",
    "        mask_np = mask.cpu().numpy()\n",
    "        mask_np = (mask_np > 0).astype(np.uint8) * 255  \n",
    "        mask_resized = cv2.resize(mask_np, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "        combined_mask = np.maximum(combined_mask, mask_resized)\n",
    "\n",
    "    base_name = os.path.basename(image_path)  \n",
    "    file_name_without_extension = os.path.splitext(base_name)[0]  \n",
    "\n",
    "    if output_folder:\n",
    "        os.makedirs(output_folder, exist_ok=True)  \n",
    "        output_path = os.path.join(output_folder, f\"{file_name_without_extension}_mask.png\")\n",
    "        cv2.imwrite(output_path, combined_mask)\n",
    "\n",
    "    if not skip_display:\n",
    "        # Display the combined mask\n",
    "        plt.imshow(combined_mask, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"Predicted mask saved to {output_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Predict on Single Image\n",
    "Replace `path_to_single_image_predict` with the path of the single image you want to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_single_image_predict = \"configure_path_here\"\n",
    "predict_with_yolo(path_to_single_image_predict, skip_display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Predict on Batch of Images\n",
    "Replace `path_to_batch_predict` with the path to the folder containing images to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_batch_predict = \"configure_path_here\"\n",
    "files = os.listdir(path_to_batch_predict)\n",
    "\n",
    "image_extensions = ['.jpeg', '.jpg', '.png']\n",
    "image_files = [f for f in files if any(f.lower().endswith(ext) for ext in image_extensions)]\n",
    "\n",
    "for image_filename in image_files:\n",
    "    image_path = os.path.join(path_to_batch_predict, image_filename)\n",
    "    \n",
    "    try:\n",
    "        predict_with_yolo(image_path, output_folder)  \n",
    "    except Exception as e:\n",
    "        # In case of error, print the error with the image path and error message\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
