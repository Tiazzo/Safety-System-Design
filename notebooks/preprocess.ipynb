{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "This notebook is responsible for preprocessing the images. Run thi notebook if you want to train the models.\n",
    "\n",
    "Contents:\n",
    "- Crop (Remove background noise)\n",
    "- Flip (Every car should be in the same direction)\n",
    "- Scale (Scale all cars according to a reference car)\n",
    "- Execute (Run the scripts)\n",
    "\n",
    "What will you need to do?\n",
    "- Create a dir named *data* in the root folder of the project\n",
    "- Download the GP22 Dataset (https://zenodo.org/records/6366808), both Images.zip and Labels.zip\n",
    "- Run code block below to generate directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure paths here \n",
    "path_to_orientation_model = \"../data/models/orientation_model/best_model.pth\"\n",
    "path_to_gp22_images = \"../data/GP22/images\"\n",
    "path_to_gp22_labels = \"../data/GP22/labels\"\n",
    "path_to_json_labels = \"../data/json_labels\"\n",
    "\n",
    "# path_to_reference_car_label # Configured under 3rd code block in --> Execute\n",
    "output_dir_images_cropped = \"../data/processed/cropped\"\n",
    "output_dir_images_flipped = \"../data/processed/flipped_images\"\n",
    "output_dir_labels_flipped = \"../data/processed/flipped_labels\"\n",
    "output_dir_images_scaled = \"../data/processed/scaled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3 Directories generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_directories_exist(paths):\n",
    "    \"\"\" \n",
    "    Ensure that the directories in the given paths exist. If they do not, create them.\n",
    "    Args:\n",
    "        paths (list): List of paths to directories to ensure exist.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    for path in paths:\n",
    "        directory = path if path.endswith('/') or '.' not in os.path.basename(path) else os.path.dirname(path)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "            print(f\"Created directory: {directory}\")\n",
    "        else:\n",
    "            print(f\"Directory already exists: {directory}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure paths here\n",
    "paths = [\n",
    "    \"../data\",\n",
    "    \"../data/models/orientation_model/best_model.pth\",\n",
    "    \"../data/GP22/images/\",\n",
    "    \"../data/GP22/labels/\",\n",
    "    \"../data/json_labels/\",\n",
    "    \"../data/processed/cropped/\",\n",
    "    \"../data/processed/flipped_images/\",\n",
    "    \"../data/processed/flipped_labels/\",\n",
    "    \"../data/processed/scaled\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_directories_exist(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.4 Unzip of GP22 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert the downloaded Images.zip and Labels.zip into the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "base_dir = \"../data/GP22\"\n",
    "images_zip = \"../data/Images.zip\"\n",
    "labels_zip = \"../data/Labels.zip\"\n",
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "labels_dir = os.path.join(base_dir, \"labels\")\n",
    "\n",
    "# Function to remove __MACOSX folder if it exists\n",
    "def remove_macosx_folder(base_dir):\n",
    "    macosx_path = os.path.join(base_dir, \"__MACOSX\")\n",
    "    if os.path.exists(macosx_path):\n",
    "        shutil.rmtree(macosx_path)\n",
    "        print(f\"Removed {macosx_path}.\")\n",
    "\n",
    "# Check and unzip Images.zip\n",
    "if os.path.exists(images_zip):\n",
    "    if not os.listdir(images_dir):\n",
    "        print(f\"Extracting {images_zip} to {images_dir}...\")\n",
    "        with zipfile.ZipFile(images_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_dir) \n",
    "        print(f\"Extraction complete: {images_dir}\")\n",
    "        os.remove(images_zip)\n",
    "        print(f\"Deleted {images_zip}.\")\n",
    "        remove_macosx_folder(base_dir)\n",
    "    else:\n",
    "        print(f\"{images_dir} already contains files. Skipping extraction of {images_zip}.\")\n",
    "else:\n",
    "    print(f\"{images_zip} not found.\")\n",
    "\n",
    "# Check and unzip Labels.zip\n",
    "if os.path.exists(labels_zip):\n",
    "    if not os.listdir(labels_dir):\n",
    "        print(f\"Extracting {labels_zip} to {labels_dir}...\")\n",
    "        with zipfile.ZipFile(labels_zip, 'r') as zip_ref:\n",
    "            zip_ref.extractall(base_dir)\n",
    "        print(f\"Extraction complete: {labels_dir}\")\n",
    "        os.remove(labels_zip)\n",
    "        print(f\"Deleted {labels_zip}.\")\n",
    "        remove_macosx_folder(base_dir)\n",
    "    else:\n",
    "        print(f\"{labels_dir} already contains files. Skipping extraction of {labels_zip}.\")\n",
    "else:\n",
    "    print(f\"{labels_zip} not found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Crop\n",
    "Removing background noise slightly improves model performance.\n",
    "The following code block will: \n",
    "- Use GP22 labels to process the flipped images and remove background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_out_background(images_dir, labels_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images in a directory and crop out the background using bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        images_dir (str): Path to the directory containing the images.\n",
    "        labels_dir (str): Path to the directory containing the labels.\n",
    "        output_dir (str): Path to the directory to save the cropped images.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for image_path in Path(images_dir).glob(\"*.jpg\"):\n",
    "        label_path = Path(labels_dir) / f\"{image_path.stem}.txt\"\n",
    "\n",
    "        if not label_path.exists():\n",
    "            print(f\"No label found for {image_path.name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        image = cv2.imread(str(image_path))\n",
    "        if image is None:\n",
    "            print(f\"Could not read the image at {image_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        img_height, img_width = image.shape[:2]\n",
    "\n",
    "        mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        bounding_boxes = []\n",
    "        with open(label_path, 'r') as file:\n",
    "            for line in file:\n",
    "                class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                bounding_boxes.append([x_center, y_center, width, height])\n",
    "\n",
    "        for (x_center, y_center, width, height) in bounding_boxes:\n",
    "            x = int((x_center - width / 2) * img_width)\n",
    "            y = int((y_center - height / 2) * img_height)\n",
    "            w = int(width * img_width)\n",
    "            h = int(height * img_height)\n",
    "\n",
    "            cv2.rectangle(mask, (x, y), (x + w, y + h), 255, thickness=-1)\n",
    "\n",
    "        result = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "        output_path = Path(output_dir) / image_path.name\n",
    "        cv2.imwrite(str(output_path), result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Flip\n",
    "Every car should be pointing in the same direction.\n",
    "The following code blocks will:\n",
    "- Load the orientation model\n",
    "- Predict whether a car is pointing left or right\n",
    "- Flip the corresponding label of each car\n",
    "- Flip the image of the car itself\n",
    "\n",
    "We have chosen to flip cars to the **left**. That is, nose points to the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load the orientation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def load_orientation_model(checkpoint_path):\n",
    "    \"\"\"\n",
    "    Loads the trained orientation model from the given checkpoint path.\n",
    "    Args:\n",
    "        checkpoint_path (str): Path to the checkpoint file.\n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded model.\n",
    "    \"\"\"\n",
    "    model = models.resnet18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 2)\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {checkpoint_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Predict orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_orientation(model, image_path):\n",
    "    \"\"\"\n",
    "    Predicts the orientation of the car in the image.\n",
    "    Args:\n",
    "        model (torch.nn.Module): The orientation model.\n",
    "        image_path (str): Path to the image.\n",
    "    Returns:\n",
    "        str: The predicted orientation (\"left\" or \"right\").\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        return \"left\" if predicted.item() == 0 else \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip x-coordinates of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_labels_x(label_path, output_label_dir):\n",
    "    \"\"\"\n",
    "    Flips the x-coordinates of labels and saves them to a new directory.\n",
    "\n",
    "    Args:\n",
    "        label_path (str): Path to the label file.\n",
    "        output_label_dir (str): Path to the directory to save the flipped labels.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "    flipped_labels = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            class_id, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "            x_center = 1 - x_center  # Flip the x-coordinate\n",
    "            flipped_labels.append(f\"{int(class_id)} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "\n",
    "    output_label_path = os.path.join(output_label_dir, os.path.basename(label_path))\n",
    "    with open(output_label_path, 'w') as f:\n",
    "        f.write(\"\\n\".join(flipped_labels))\n",
    "    \n",
    "    print(f\"Flipped labels saved to {output_label_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_image(image_path, output_image_dir):\n",
    "    \"\"\"\n",
    "    Flips an image horizontally and saves it to the output directory.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        output_image_dir (str): Path to the directory to save the flipped image.\n",
    "    Returns:\n",
    "        str: Path to the saved flipped image.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_image_dir, exist_ok=True)\n",
    "\n",
    "    image = cv2.imread(str(image_path))\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "    output_image_path = os.path.join(output_image_dir, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_image_path, flipped_image)\n",
    "    \n",
    "    print(f\"Flipped image saved to {output_image_path}\")\n",
    "    return output_image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Flip Images and Labels\n",
    "Run this to process all images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_images_and_labels(model, images_dir, labels_dir, output_image_dir, output_label_dir):\n",
    "    \"\"\"\n",
    "    Processes all images: identifies flipped images, flips them, and flips the labels' x-coordinates.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The orientation model.\n",
    "        images_dir (str): Path to the directory containing the images.\n",
    "        labels_dir (str): Path to the directory containing the labels.\n",
    "        output_image_dir (str): Path to the directory to save the flipped images.\n",
    "        output_label_dir (str): Path to the directory to save the flipped labels.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_image_dir, exist_ok=True)\n",
    "    os.makedirs(output_label_dir, exist_ok=True)\n",
    "\n",
    "    for image_path in Path(images_dir).glob(\"*.jpg\"):\n",
    "        label_path = Path(labels_dir) / f\"{image_path.stem}.txt\"\n",
    "        \n",
    "        if label_path.exists():\n",
    "            orientation = predict_orientation(model, str(image_path))\n",
    "            flipped = False\n",
    "\n",
    "            if orientation == \"right\":\n",
    "                flipped = True\n",
    "                flip_image(str(image_path), output_image_dir)\n",
    "                flip_labels_x(str(label_path), output_label_dir)\n",
    "            else:\n",
    "                shutil.copy(str(image_path), os.path.join(output_image_dir, image_path.name))\n",
    "                shutil.copy(str(label_path), os.path.join(output_label_dir, label_path.name))\n",
    "                print(f\"Image and labels copied to {output_image_dir} and {output_label_dir}\")\n",
    "        else:\n",
    "            print(f\"Label file not found for {image_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Scale\n",
    "Cars should be relative to each other in size.\n",
    "The following code blocks will:\n",
    "- Calculate rim area (used as a reference when scaling)\n",
    "- Calculate scaling factor (based on reference car and current car)\n",
    "- Scale images and update labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rim area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rim_area_of_front_wheel(label_path, resolution=1024):\n",
    "    \"\"\"\n",
    "    Returns {area} of front-wheel rim\n",
    "    Important! Car nose should be pointing left\n",
    "\n",
    "    Args:\n",
    "        label_path (str): Path to the label file.\n",
    "        resolution (int): Resolution of the image.\n",
    "    Returns:\n",
    "        float: Area of the front-wheel rim in the image.\n",
    "    \"\"\"\n",
    "    smallest_x = float(\"inf\")\n",
    "    smallest_box = None\n",
    "\n",
    "    with open(label_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            class_id, x_center, y_center, width, height = line.strip().split()\n",
    "            if int(class_id) == 1: \n",
    "                x_center = float(x_center)\n",
    "                if x_center < smallest_x:\n",
    "                    smallest_x = x_center\n",
    "                    smallest_box = (float(width), float(height))\n",
    "\n",
    "    if smallest_box:\n",
    "        width, height = smallest_box\n",
    "        area = width * height * (resolution**2)\n",
    "        return area\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scaling factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_area(rim_area_reference_car, rim_area_current_car):\n",
    "    \"\"\"\n",
    "    Calculate the scaling factor to adjust the dimensions of the current car\n",
    "    so that its area matches the area of the reference car.\n",
    "\n",
    "    Args:\n",
    "        rim_area_reference_car (float): Area of the front-wheel rim of the reference car.\n",
    "        rim_area_current_car (float): Area of the front-wheel rim of the current car.\n",
    "    Returns:\n",
    "        float: Scaling factor to adjust the dimensions of the current car.\n",
    "    \"\"\"\n",
    "    if rim_area_reference_car <= 0 or rim_area_current_car <= 0:\n",
    "        raise ValueError(\"Both areas must be positive numbers.\")\n",
    "    \n",
    "    scaling_factor = (rim_area_reference_car / rim_area_current_car) ** 0.5\n",
    "    \n",
    "    return scaling_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Scale JSON labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_json_labels(json_path, scaling_factor, offset_x, offset_y, labels_dir):\n",
    "    \"\"\"\n",
    "    Updates the JSON labels to match the scaled and padded image.\n",
    "\n",
    "    Args:\n",
    "        json_path (str): Path to the JSON label file.\n",
    "        scaling_factor (float): Scaling factor to adjust the dimensions of the current car.\n",
    "        offset_x (int): The x-offset to center the points.\n",
    "        offset_y (int): The y-offset to center the points.\n",
    "        labels_dir (str): Path to the directory to save the updated JSON labels.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # Scale and offset points\n",
    "    for shape in data['shapes']:\n",
    "        new_points = []\n",
    "        for point in shape['points']:\n",
    "            # First scale the points\n",
    "            scaled_x = point[0] * scaling_factor\n",
    "            scaled_y = point[1] * scaling_factor\n",
    "            \n",
    "            # Then add the positive offset to center the points\n",
    "            scaled_x += offset_x  # Remove the negative sign\n",
    "            scaled_y += offset_y  # Remove the negative sign\n",
    "\n",
    "            # Only include points that fall within the 1024x1024 canvas\n",
    "            if 0 <= scaled_x < 1024 and 0 <= scaled_y < 1024:\n",
    "                new_points.append([scaled_x, scaled_y])\n",
    "\n",
    "        shape['points'] = new_points\n",
    "\n",
    "    # Update image metadata\n",
    "    data['imageWidth'] = 1024\n",
    "    data['imageHeight'] = 1024\n",
    "\n",
    "    # Save updated JSON\n",
    "    json_filename = os.path.basename(json_path)\n",
    "    updated_json_path = os.path.join(labels_dir, json_filename)\n",
    "\n",
    "    with open(updated_json_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Scale images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_and_crop_image(image_path, scaling_factor, label_path, json_label_path, output_dir):\n",
    "    \"\"\"\n",
    "    Scales an image by a given scaling factor, ensures it is padded to 1024x1024 pixels,\n",
    "    and scales corresponding JSON labels.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image.\n",
    "        scaling_factor (float): Scaling factor to adjust the dimensions of the current car.\n",
    "        label_path (str): Path to the label file.\n",
    "        json_label_path (str): Path to the JSON label file.\n",
    "        output_dir (str): Path to the directory to save the scaled image.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if scaling_factor <= 0:\n",
    "        raise ValueError(\"Scaling factor must be a positive number.\")\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "\n",
    "    # Get original dimensions\n",
    "    original_height, original_width = image.shape[:2]\n",
    "\n",
    "    # Compute new dimensions\n",
    "    new_width = int(original_width * scaling_factor)\n",
    "    new_height = int(original_height * scaling_factor)\n",
    "\n",
    "    # Resize the image using OpenCV\n",
    "    scaled_image = cv2.resize(\n",
    "        image, (new_width, new_height), interpolation=cv2.INTER_LINEAR\n",
    "    )\n",
    "\n",
    "    # Ensure the image is 1024x1024 by padding with black if necessary\n",
    "    target_size = 1024\n",
    "    padded_image = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
    "\n",
    "    # Center the scaled image in the 1024x1024 canvas\n",
    "    offset_x = (target_size - new_width) // 2 if new_width < target_size else 0\n",
    "    offset_y = (target_size - new_height) // 2 if new_height < target_size else 0\n",
    "\n",
    "    insert_width = min(new_width, target_size)\n",
    "    insert_height = min(new_height, target_size)\n",
    "\n",
    "    padded_image[offset_y:offset_y+insert_height, offset_x:offset_x+insert_width] = \\\n",
    "        scaled_image[:insert_height, :insert_width]\n",
    "\n",
    "    # Create directories for images and labels\n",
    "    images_dir = os.path.join(output_dir, \"images\")\n",
    "    labels_dir = os.path.join(output_dir, \"labels\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    os.makedirs(labels_dir, exist_ok=True)\n",
    "\n",
    "    # Save padded image\n",
    "    image_filename = os.path.basename(image_path)\n",
    "    padded_image_path = os.path.join(images_dir, image_filename)\n",
    "    cv2.imwrite(padded_image_path, padded_image)\n",
    "\n",
    "    # Update JSON labels\n",
    "    update_json_labels(json_label_path, scaling_factor, offset_x, offset_y, labels_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute\n",
    "The following code blocks will execute corresponding code for:\n",
    "- Removing background\n",
    "- Flipping images and labels\n",
    "- Scaling images and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_gp22_images          # Directory with GP22 images\n",
    "path_to_gp22_labels          # Directory with bounding box labels (text files)\n",
    "output_dir_images_cropped    # Directory to save cropped images\n",
    "\n",
    "crop_out_background(path_to_gp22_images, path_to_gp22_labels, output_dir_images_cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_orientation_model   # Directory with orientation model\n",
    "output_dir_images_cropped   # Directory with cropped images\n",
    "path_to_json_labels         # Directory with JSON labels\n",
    "output_dir_images_flipped   # Directory to save flipped images\n",
    "output_dir_labels_flipped   # Directory to save flipped labels\n",
    "\n",
    "model = load_orientation_model(path_to_orientation_model)\n",
    "\n",
    "flip_images_and_labels(\n",
    "    model, \n",
    "    output_dir_images_cropped, \n",
    "    path_to_json_labels, \n",
    "    output_dir_images_flipped, \n",
    "    output_dir_labels_flipped\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_all_images_and_labels(reference_label_path, images_folder, labels_folder, json_labels_folder, output_folder, resolution=1024):\n",
    "    \"\"\"\n",
    "    Scales images and corresponding labels\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    images_output_dir = os.path.join(output_folder, \"images\")\n",
    "    labels_output_dir = os.path.join(output_folder, \"labels\")\n",
    "    os.makedirs(images_output_dir, exist_ok=True)\n",
    "    os.makedirs(labels_output_dir, exist_ok=True)\n",
    "\n",
    "    # Ensure the reference label path is valid\n",
    "    if not os.path.exists(reference_label_path):\n",
    "        print(f\"Reference label path {reference_label_path} does not exist.\")\n",
    "        return\n",
    "    \n",
    "    reference_area = calculate_rim_area_of_front_wheel(reference_label_path, resolution)\n",
    "    print(f\"Reference area: {reference_area}\")\n",
    "    \n",
    "    # Loop through label files in the label folder\n",
    "    print(f\"Looking for label files in: {labels_folder}\")\n",
    "    for label_file in os.listdir(labels_folder):\n",
    "        if label_file.endswith(\".txt\"):\n",
    "            print(f\"Found label file: {label_file}\")\n",
    "            label_path = os.path.join(labels_folder, label_file)\n",
    "            \n",
    "            current_area = calculate_rim_area_of_front_wheel(label_path, resolution)\n",
    "            print(f\"Current area for {label_file}: {current_area}\")\n",
    "            \n",
    "            # Get corresponding image file\n",
    "            image_name = label_file.replace(\".txt\", \"_aug_0.jpg\")  # Assuming images are .jpg\n",
    "            image_path = Path(images_folder) / image_name  # Use Path to handle path joining\n",
    "            image_path = str(image_path).replace(\"\\\\\", \"/\")\n",
    "            print(f\"Looking for image: {image_path}\")\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"Image {image_name} corresponding to label {label_file} does not exist. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Get corresponding JSON label file (assumes the JSON label has the same name as the .txt label)\n",
    "            json_label_name = label_file.replace(\".txt\", \".json\")\n",
    "            json_label_path = os.path.join(json_labels_folder, json_label_name)\n",
    "            print(f\"Looking for JSON label: {json_label_path}\")\n",
    "            \n",
    "            if not os.path.exists(json_label_path):\n",
    "                print(f\"JSON label {json_label_name} for {label_file} does not exist. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"Processing: {image_name} and {label_file}\")\n",
    "\n",
    "            scaling_factor = compare_area(reference_area, current_area)\n",
    "            print(f\"Scaling factor for {label_file}: {scaling_factor}\")\n",
    "\n",
    "            # Process the image and label\n",
    "            try:\n",
    "                scale_and_crop_image(image_path, scaling_factor, label_path, json_label_path, output_folder)\n",
    "                print(f\"Processed and saved: {image_name} and {label_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_name} and {label_file}: {e}\")\n",
    "\n",
    "\n",
    "path_to_reference_car_label = \"../data/GP22/labels/B_Ren_12.txt\" # Directory to chosen reference car\n",
    "output_dir_images_flipped   # Directory to images of flipped cars\n",
    "output_dir_labels_flipped   # Directory to labels of flipped cars\n",
    "output_dir_images_scaled           # Directory to save images and labels of scaled cars\n",
    "\n",
    "scale_all_images_and_labels(\n",
    "    path_to_reference_car_label, \n",
    "    output_dir_images_flipped, \n",
    "    path_to_gp22_labels, \n",
    "    output_dir_labels_flipped, \n",
    "    output_dir_images_scaled\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
